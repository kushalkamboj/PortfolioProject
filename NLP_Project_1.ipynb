{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvcBaeagalc46HVDLmFbiR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushalkamboj/PortfolioProject/blob/main/NLP_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WPmPrFqItyXa"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnbPWNslt2Mr",
        "outputId": "1fb8b8b8-8e28-4af9-8f22-58498a2558fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Reading the .csv file using Pandas\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv('K8 Reviews v0.2.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "hccyJMZEt5wh",
        "outputId": "c7c8925c-0750-4709-a3d2-94fa2e1d8688"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6265718a-a1c6-4885-aff6-825ae0455cdb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6265718a-a1c6-4885-aff6-825ae0455cdb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving K8 Reviews v0.2.csv to K8 Reviews v0.2.csv\n",
            "   sentiment                                             review\n",
            "0          1             Good but need updates and improvements\n",
            "1          0  Worst mobile i have bought ever, Battery is dr...\n",
            "2          1  when I will get my 10% cash back.... its alrea...\n",
            "3          1                                               Good\n",
            "4          0  The worst phone everThey have changed the last...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Normalizing casings and extracting text into a list\n",
        "reviews = df['review'].str.lower().tolist()\n"
      ],
      "metadata": {
        "id": "3rI173Vht8Vz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Tokenizing the reviews\n",
        "tokenized_reviews = [word_tokenize(review) for review in reviews]\n"
      ],
      "metadata": {
        "id": "j-hUBM_WuGTo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Performing parts-of-speech tagging\n",
        "tagged_reviews = [pos_tag(tokens) for tokens in tokenized_reviews]\n"
      ],
      "metadata": {
        "id": "-LwaMP6JuLCW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5: Limiting data to only terms with noun tags\n",
        "noun_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "nouns_only = [[token for token, tag in review if tag in noun_tags] for review in tagged_reviews]"
      ],
      "metadata": {
        "id": "J11iPWfQuNwv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 6: Lemmatizing the tokens\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_reviews = [[lemmatizer.lemmatize(token) for token in review] for review in nouns_only]"
      ],
      "metadata": {
        "id": "_KeWZkIYuTJa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7: Removing stopwords and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "cleaned_reviews = [[token for token in review if token not in stop_words and token.isalpha()] for review in lemmatized_reviews]"
      ],
      "metadata": {
        "id": "fiWM17M3uTwX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 8: Creating a topic model using LDA with 12 topics\n",
        "dictionary = Dictionary(cleaned_reviews)\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in cleaned_reviews]\n",
        "lda_model = LdaModel(doc_term_matrix, num_topics=12, id2word=dictionary, passes=50)\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f'Topic: {idx}\\nWords: {topic}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2nGUZx5uWSo",
        "outputId": "108c63c1-0556-498a-d789-3b242ffc9fdc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0\n",
            "Words: 0.086*\"call\" + 0.078*\"option\" + 0.067*\"screen\" + 0.062*\"waste\" + 0.032*\"cast\" + 0.032*\"money\" + 0.032*\"work\" + 0.024*\"application\" + 0.024*\"notification\" + 0.023*\"contact\"\n",
            "\n",
            "Topic: 1\n",
            "Words: 0.349*\"product\" + 0.062*\"amazon\" + 0.044*\"charger\" + 0.026*\"experience\" + 0.021*\"service\" + 0.021*\"replacement\" + 0.020*\"delivery\" + 0.018*\"lenovo\" + 0.018*\"purchase\" + 0.015*\"customer\"\n",
            "\n",
            "Topic: 2\n",
            "Words: 0.095*\"sim\" + 0.083*\"everything\" + 0.066*\"budget\" + 0.050*\"jio\" + 0.043*\"volta\" + 0.039*\"delivery\" + 0.037*\"side\" + 0.033*\"excellent\" + 0.028*\"support\" + 0.024*\"awesome\"\n",
            "\n",
            "Topic: 3\n",
            "Words: 0.376*\"phone\" + 0.048*\"feature\" + 0.035*\"hai\" + 0.025*\"h\" + 0.014*\"ho\" + 0.013*\"plz\" + 0.010*\"killer\" + 0.010*\"hi\" + 0.009*\"function\" + 0.009*\"company\"\n",
            "\n",
            "Topic: 4\n",
            "Words: 0.104*\"money\" + 0.097*\"device\" + 0.052*\"value\" + 0.040*\"return\" + 0.040*\"update\" + 0.036*\"dolby\" + 0.027*\"lenovo\" + 0.021*\"atmos\" + 0.021*\"policy\" + 0.019*\"version\"\n",
            "\n",
            "Topic: 5\n",
            "Words: 0.265*\"battery\" + 0.095*\"phone\" + 0.052*\"backup\" + 0.043*\"time\" + 0.043*\"day\" + 0.041*\"hour\" + 0.029*\"life\" + 0.028*\"camera\" + 0.027*\"issue\" + 0.026*\"charge\"\n",
            "\n",
            "Topic: 6\n",
            "Words: 0.335*\"performance\" + 0.070*\"camera\" + 0.059*\"look\" + 0.048*\"processor\" + 0.044*\"star\" + 0.039*\"super\" + 0.026*\"piece\" + 0.024*\"fast\" + 0.017*\"body\" + 0.012*\"yesterday\"\n",
            "\n",
            "Topic: 7\n",
            "Words: 0.172*\"camera\" + 0.083*\"quality\" + 0.065*\"phone\" + 0.024*\"feature\" + 0.023*\"mode\" + 0.022*\"sound\" + 0.020*\"display\" + 0.020*\"speaker\" + 0.013*\"music\" + 0.013*\"video\"\n",
            "\n",
            "Topic: 8\n",
            "Words: 0.123*\"problem\" + 0.123*\"phone\" + 0.092*\"issue\" + 0.046*\"heating\" + 0.040*\"network\" + 0.030*\"service\" + 0.028*\"month\" + 0.025*\"lenovo\" + 0.024*\"time\" + 0.020*\"day\"\n",
            "\n",
            "Topic: 9\n",
            "Words: 0.380*\"mobile\" + 0.048*\"glass\" + 0.044*\"superb\" + 0.033*\"expectation\" + 0.025*\"gorilla\" + 0.021*\"screen\" + 0.019*\"quality\" + 0.018*\"class\" + 0.013*\"result\" + 0.010*\"nice\"\n",
            "\n",
            "Topic: 10\n",
            "Words: 0.165*\"phone\" + 0.152*\"price\" + 0.060*\"range\" + 0.028*\"feature\" + 0.022*\"headphone\" + 0.020*\"earphone\" + 0.019*\"thanks\" + 0.018*\"specification\" + 0.017*\"worth\" + 0.016*\"box\"\n",
            "\n",
            "Topic: 11\n",
            "Words: 0.153*\"note\" + 0.079*\"lenovo\" + 0.067*\"software\" + 0.044*\"ram\" + 0.036*\"system\" + 0.030*\"card\" + 0.029*\"smartphone\" + 0.026*\"memory\" + 0.026*\"update\" + 0.021*\"gb\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 8.2: Computing the coherence of the model with the c_v metric\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=cleaned_reviews, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print(f'Coherence Score: {coherence_lda}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5WnERMhuZGK",
        "outputId": "b9da7b50-0b7a-401e-df58-73320d7190ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score: 0.5313391596196517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of all the topics and their top keywords\n",
        "num_topics=12\n",
        "topic_keywords = lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False)"
      ],
      "metadata": {
        "id": "LsQ9uZbfytVc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary to map topic numbers to their coherence scores\n",
        "topic_coherences = {}\n",
        "for i in range(num_topics):\n",
        "    # convert the topic keywords to a list of token ids\n",
        "    topic_tokens = [token[0] for token in topic_keywords[i][1]]\n",
        "    topic_ids = [dictionary.token2id[token] for token in topic_tokens if token in dictionary.token2id]\n",
        "    \n",
        "    # calculate the coherence score using the token ids\n",
        "    cm = CoherenceModel(topics=[topic_ids], texts=cleaned_reviews, dictionary=dictionary, coherence='c_v')\n",
        "    topic_coherences[i] = cm.get_coherence()"
      ],
      "metadata": {
        "id": "kh_kmHz8zm6n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the topics by their coherence scores (in descending order)\n",
        "sorted_topics = sorted(topic_coherences.items(), key=lambda x: x[1], reverse=True)\n"
      ],
      "metadata": {
        "id": "swGxU1oy1abz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out the topics and their coherence scores\n",
        "print(\"Topics and Coherence Scores:\")\n",
        "for topic in sorted_topics:\n",
        "    print(f\"Topic {topic[0]}: {topic[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLnzQgRozvfM",
        "outputId": "d5df9f27-f75a-4da9-f3da-7788886d8e49"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics and Coherence Scores:\n",
            "Topic 7: 0.8215510499955329\n",
            "Topic 11: 0.7135453479962782\n",
            "Topic 1: 0.7127067479765388\n",
            "Topic 8: 0.6925356483974601\n",
            "Topic 5: 0.6922234386603883\n",
            "Topic 0: 0.6272983178915674\n",
            "Topic 4: 0.5442960437009777\n",
            "Topic 2: 0.4184792210702492\n",
            "Topic 6: 0.38841443587324326\n",
            "Topic 9: 0.3572777713938146\n",
            "Topic 3: 0.3240975900223187\n",
            "Topic 10: 0.3130043966634967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine which topics can be combined\n",
        "# we can use a threshold coherence score to decide which topics are coherent enough to be combined\n",
        "threshold = 0.4\n",
        "print(f\"\\nTopics to Combine (coherence score >= {threshold}):\")\n",
        "for i in range(num_topics):\n",
        "    if topic_coherences[sorted_topics[i][0]] >= threshold:\n",
        "        print(f\"Topic {sorted_topics[i][0]}: {topic_keywords[sorted_topics[i][0]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMsUR7MkzSnW",
        "outputId": "b804c72c-5f30-4006-d09a-cca30dab44fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topics to Combine (coherence score >= 0.4):\n",
            "Topic 7: (7, [('camera', 0.17169197), ('quality', 0.08288315), ('phone', 0.06487694), ('feature', 0.02376089), ('mode', 0.022651972), ('sound', 0.022288702), ('display', 0.020143854), ('speaker', 0.019672541), ('music', 0.013392466), ('video', 0.013227598), ('note', 0.012360801), ('speed', 0.012237436)])\n",
            "Topic 11: (11, [('note', 0.15336715), ('lenovo', 0.07887897), ('software', 0.06673406), ('ram', 0.04422346), ('system', 0.03579163), ('card', 0.030276945), ('smartphone', 0.028753325), ('memory', 0.025523987), ('update', 0.025511593), ('gb', 0.021250602), ('apps', 0.019339235), ('model', 0.018802516)])\n",
            "Topic 1: (1, [('product', 0.3493943), ('amazon', 0.062465373), ('charger', 0.04415039), ('experience', 0.026239965), ('service', 0.021369549), ('replacement', 0.020739608), ('delivery', 0.019622166), ('lenovo', 0.018209707), ('purchase', 0.01802833), ('customer', 0.015337502), ('day', 0.014608677), ('month', 0.0133802295)])\n",
            "Topic 8: (8, [('problem', 0.1232286), ('phone', 0.12292394), ('issue', 0.09158642), ('heating', 0.04593438), ('network', 0.039899006), ('service', 0.029570129), ('month', 0.028187968), ('lenovo', 0.024560282), ('time', 0.024403995), ('day', 0.019875353), ('note', 0.016375195), ('handset', 0.015012397)])\n",
            "Topic 5: (5, [('battery', 0.26529637), ('phone', 0.095073745), ('backup', 0.051952366), ('time', 0.0432355), ('day', 0.042734288), ('hour', 0.040856153), ('life', 0.028777037), ('camera', 0.028413633), ('issue', 0.026792414), ('charge', 0.025929201), ('heat', 0.02374964), ('drain', 0.019250285)])\n",
            "Topic 0: (0, [('call', 0.08556305), ('option', 0.0780156), ('screen', 0.066709384), ('waste', 0.061963465), ('cast', 0.03243151), ('money', 0.031915992), ('work', 0.03175208), ('application', 0.023660362), ('notification', 0.023547266), ('contact', 0.023146888), ('voice', 0.021155471), ('message', 0.018531127)])\n",
            "Topic 4: (4, [('money', 0.10387639), ('device', 0.0973425), ('value', 0.051512793), ('return', 0.039743837), ('update', 0.039578233), ('dolby', 0.036112994), ('lenovo', 0.027179928), ('atmos', 0.02128247), ('policy', 0.021030027), ('version', 0.019376574), ('person', 0.012542092), ('week', 0.012026582)])\n",
            "Topic 2: (2, [('sim', 0.095198326), ('everything', 0.082877286), ('budget', 0.06598931), ('jio', 0.05004102), ('volta', 0.042747803), ('delivery', 0.038684454), ('side', 0.037141927), ('excellent', 0.033423148), ('support', 0.02772056), ('awesome', 0.024315314), ('slot', 0.020046448), ('gud', 0.018912181)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = LdaModel(corpus=doc_term_matrix,id2word=dictionary,num_topics=num_topics,random_state=42,passes=10,per_word_topics=True)\n",
        "\n",
        "# calculate the coherence score of the model\n",
        "cm = CoherenceModel(model=lda_model, texts=cleaned_reviews, dictionary=dictionary, coherence='c_v')\n",
        "coherence = cm.get_coherence()\n",
        "\n",
        "print(f\"Coherence score: {coherence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-r7LS3v3tdv",
        "outputId": "93240986-d346-444e-ba65-ef4fbc4249d9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score: 0.629370123043419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpret the topics and name them based on the top terms\n",
        "topic_names = []\n",
        "for topic in topic_keywords:\n",
        "    top_terms = [term[0] for term in topic[1]]\n",
        "    topic_name = ', '.join(top_terms)\n",
        "    topic_names.append(topic_name)\n",
        "\n",
        "# Create a table with the topic name and the top 10 terms for each topic\n",
        "\n",
        "terms_table = pd.DataFrame(columns=['Topic Name', 'Top 10 Terms'])\n",
        "\n",
        "for i, topic in enumerate(topic_keywords):\n",
        "    top_terms = [term[0] for term in topic[1]]\n",
        "    topic_name = topic_names[i]\n",
        "    row = {'Topic Name': topic_name, 'Top 10 Terms': top_terms}\n",
        "    terms_table = terms_table.append(row, ignore_index=True)\n",
        "\n",
        "# Print the table\n",
        "print(terms_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKzermHv7JZw",
        "outputId": "fbc380df-cd11-4ae7-a872-45705b35b46f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Topic Name  \\\n",
            "0   call, option, screen, waste, cast, money, work...   \n",
            "1   product, amazon, charger, experience, service,...   \n",
            "2   sim, everything, budget, jio, volta, delivery,...   \n",
            "3   phone, feature, hai, h, ho, plz, killer, hi, f...   \n",
            "4   money, device, value, return, update, dolby, l...   \n",
            "5   battery, phone, backup, time, day, hour, life,...   \n",
            "6   performance, camera, look, processor, star, su...   \n",
            "7   camera, quality, phone, feature, mode, sound, ...   \n",
            "8   problem, phone, issue, heating, network, servi...   \n",
            "9   mobile, glass, superb, expectation, gorilla, s...   \n",
            "10  phone, price, range, feature, headphone, earph...   \n",
            "11  note, lenovo, software, ram, system, card, sma...   \n",
            "\n",
            "                                         Top 10 Terms  \n",
            "0   [call, option, screen, waste, cast, money, wor...  \n",
            "1   [product, amazon, charger, experience, service...  \n",
            "2   [sim, everything, budget, jio, volta, delivery...  \n",
            "3   [phone, feature, hai, h, ho, plz, killer, hi, ...  \n",
            "4   [money, device, value, return, update, dolby, ...  \n",
            "5   [battery, phone, backup, time, day, hour, life...  \n",
            "6   [performance, camera, look, processor, star, s...  \n",
            "7   [camera, quality, phone, feature, mode, sound,...  \n",
            "8   [problem, phone, issue, heating, network, serv...  \n",
            "9   [mobile, glass, superb, expectation, gorilla, ...  \n",
            "10  [phone, price, range, feature, headphone, earp...  \n",
            "11  [note, lenovo, software, ram, system, card, sm...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n",
            "<ipython-input-33-51cc24b0aac2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  terms_table = terms_table.append(row, ignore_index=True)\n"
          ]
        }
      ]
    }
  ]
}